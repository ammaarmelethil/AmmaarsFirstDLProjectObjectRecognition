{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This script was written by Ammaar Melethil starting on 2023-12-23"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84c90743e7afc598"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (1.5.16)\r\n",
      "Requirement already satisfied: six>=1.10 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from kaggle) (1.16.0)\r\n",
      "Requirement already satisfied: certifi in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from kaggle) (2023.11.17)\r\n",
      "Requirement already satisfied: python-dateutil in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from kaggle) (2.8.2)\r\n",
      "Requirement already satisfied: requests in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from kaggle) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from kaggle) (4.66.1)\r\n",
      "Requirement already satisfied: python-slugify in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from kaggle) (8.0.1)\r\n",
      "Requirement already satisfied: urllib3 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from kaggle) (1.26.18)\r\n",
      "Requirement already satisfied: bleach in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from kaggle) (4.1.0)\r\n",
      "Requirement already satisfied: packaging in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from bleach->kaggle) (23.1)\r\n",
      "Requirement already satisfied: webencodings in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from bleach->kaggle) (0.5.1)\r\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from requests->kaggle) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from requests->kaggle) (3.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:25:34.699653Z",
     "start_time": "2023-12-27T21:25:33.420874Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Configuring the path of Kaggle.json file\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:25:35.107761Z",
     "start_time": "2023-12-27T21:25:34.702142Z"
    }
   },
   "id": "1f20ab66b2bbde9c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10.zip: Skipping, found more recently modified local copy (use --force to force download)\r\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 Dataset api\n",
    "!kaggle competitions download -c cifar-10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:25:36.634056Z",
     "start_time": "2023-12-27T21:25:35.108832Z"
    }
   },
   "id": "2672a9b0411e14a8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete\n"
     ]
    }
   ],
   "source": [
    "# Extracting from the zip file\n",
    "from zipfile import ZipFile\n",
    "dataset = 'cifar-10.zip'\n",
    "\n",
    "with ZipFile(dataset, 'r') as zip:\n",
    "    zip.extractall()\n",
    "    print('Extraction complete')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:25:37.711526Z",
     "start_time": "2023-12-27T21:25:36.635639Z"
    }
   },
   "id": "32c85bc0af68989c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar10ObjectRecognition.ipynb test.7z\r\n",
      "README.md                      \u001B[34mtrain\u001B[m\u001B[m\r\n",
      "cifar-10.zip                   train.7z\r\n",
      "kaggle.json                    trainLabels.csv\r\n",
      "sampleSubmission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:25:37.870445Z",
     "start_time": "2023-12-27T21:25:37.713367Z"
    }
   },
   "id": "60a2aa2cd75ab9ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want the images in 'train.7z', we extract using py7zr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "102555ca459bfdf9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py7zr in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (0.20.8)\r\n",
      "Requirement already satisfied: texttable in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from py7zr) (1.7.0)\r\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from py7zr) (3.19.0)\r\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from py7zr) (0.15.9)\r\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from py7zr) (1.1.0)\r\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from py7zr) (1.0.2)\r\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from py7zr) (0.2.3)\r\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from py7zr) (1.0.0)\r\n",
      "Collecting brotli>=1.1.0 (from py7zr)\r\n",
      "  Using cached Brotli-1.1.0-cp38-cp38-macosx_10_9_x86_64.whl.metadata (5.5 kB)\r\n",
      "Requirement already satisfied: psutil in /Users/ammaar/opt/anaconda3/envs/AmmaarsFirstDLProjectObjectRecognition/lib/python3.8/site-packages (from py7zr) (5.9.0)\r\n",
      "Using cached Brotli-1.1.0-cp38-cp38-macosx_10_9_x86_64.whl (446 kB)\r\n",
      "Installing collected packages: brotli\r\n",
      "  Attempting uninstall: brotli\r\n",
      "    Found existing installation: Brotli 1.0.9\r\n",
      "    Uninstalling Brotli-1.0.9:\r\n",
      "      Successfully uninstalled Brotli-1.0.9\r\n",
      "Successfully installed brotli-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install py7zr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:25:39.951640Z",
     "start_time": "2023-12-27T21:25:37.871727Z"
    }
   },
   "id": "448d61d3d3dfd542"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import py7zr\n",
    "archive = py7zr.SevenZipFile('train.7z', mode='r')\n",
    "archive.extractall()\n",
    "archive.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:22.472129Z",
     "start_time": "2023-12-27T21:25:39.953028Z"
    }
   },
   "id": "7377f91389e47874"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar10ObjectRecognition.ipynb test.7z\r\n",
      "README.md                      \u001B[34mtrain\u001B[m\u001B[m\r\n",
      "cifar-10.zip                   train.7z\r\n",
      "kaggle.json                    trainLabels.csv\r\n",
      "sampleSubmission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:22.649957Z",
     "start_time": "2023-12-27T21:26:22.471946Z"
    }
   },
   "id": "633c778c21e134b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that the images are extracted, we can begin processing the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91ff82d79f9ace11"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Importing the dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.144391Z",
     "start_time": "2023-12-27T21:26:22.652922Z"
    }
   },
   "id": "9d97b0bd040200ea"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "filenames = os.listdir('train')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.179014Z",
     "start_time": "2023-12-27T21:26:25.145167Z"
    }
   },
   "id": "6edbf46d0348a4ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Labels Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81e0135da909f6d8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('trainLabels.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.203577Z",
     "start_time": "2023-12-27T21:26:25.181282Z"
    }
   },
   "id": "63bc010e3efc53b9"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   id       label\n0   1        frog\n1   2       truck\n2   3       truck\n3   4        deer\n4   5  automobile\n5   6  automobile\n6   7        bird\n7   8       horse\n8   9        ship\n9  10         cat",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>frog</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>truck</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>truck</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>deer</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>automobile</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>automobile</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>bird</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>horse</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>ship</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>cat</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the data is sorted (id in ascending order), I am looking at the first 10 elements\n",
    "labels_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.245588Z",
     "start_time": "2023-12-27T21:26:25.201754Z"
    }
   },
   "id": "f0e78cf19860686c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "          id       label\n49990  49991        deer\n49991  49992        bird\n49992  49993    airplane\n49993  49994  automobile\n49994  49995    airplane\n49995  49996        bird\n49996  49997        frog\n49997  49998       truck\n49998  49999  automobile\n49999  50000  automobile",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49990</th>\n      <td>49991</td>\n      <td>deer</td>\n    </tr>\n    <tr>\n      <th>49991</th>\n      <td>49992</td>\n      <td>bird</td>\n    </tr>\n    <tr>\n      <th>49992</th>\n      <td>49993</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>49993</th>\n      <td>49994</td>\n      <td>automobile</td>\n    </tr>\n    <tr>\n      <th>49994</th>\n      <td>49995</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>49996</td>\n      <td>bird</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>49997</td>\n      <td>frog</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>49998</td>\n      <td>truck</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>49999</td>\n      <td>automobile</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>50000</td>\n      <td>automobile</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, if the last 10 elements are in order\n",
    "labels_df.tail(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.248693Z",
     "start_time": "2023-12-27T21:26:25.209590Z"
    }
   },
   "id": "de6e1002b473d7be"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "label\nfrog          5000\ntruck         5000\ndeer          5000\nautomobile    5000\nbird          5000\nhorse         5000\nship          5000\ncat           5000\ndog           5000\nairplane      5000\nName: count, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if distribution is even to ensure model can make significant predictions\n",
    "labels_df['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.251111Z",
     "start_time": "2023-12-27T21:26:25.225281Z"
    }
   },
   "id": "605719f40c47a1ea"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Numerically encoding the labels\n",
    "labels_dictionary = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "labels = [labels_dictionary[i] for i in labels_df['label']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.276611Z",
     "start_time": "2023-12-27T21:26:25.236860Z"
    }
   },
   "id": "6fe026398cc21343"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 9, 4, 1]\n",
      "[2, 6, 9, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Double-checking if encoding was performed correctly\n",
    "print(labels[0:5])\n",
    "print(labels[-5:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.278653Z",
     "start_time": "2023-12-27T21:26:25.242710Z"
    }
   },
   "id": "14b9189d5042b3de"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking a look at a sample image\n",
    "sample_image = Image.open('train/1.png') # Should be a frog\n",
    "plt.imshow(sample_image)\n",
    "plt.axis('off')  # Turn off axis numbers\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.568130Z",
     "start_time": "2023-12-27T21:26:25.249159Z"
    }
   },
   "id": "e875df3087387ab4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "id_list = list(labels_df['id'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:25.569351Z",
     "start_time": "2023-12-27T21:26:25.306659Z"
    }
   },
   "id": "870af4931bd69ec9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Image Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb9af6c6c240531a"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Converting images to numpy arrays\n",
    "train_data_folder = 'train/'\n",
    "data = []\n",
    "\n",
    "for id in id_list:\n",
    "    image = Image.open(train_data_folder + str(id) + '.png')\n",
    "    image = np.array(image)\n",
    "    data.append(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:34.555550Z",
     "start_time": "2023-12-27T21:26:25.315425Z"
    }
   },
   "id": "941de3ce3ce8581c"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "<class 'numpy.ndarray'>\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Checking if conversion was done correctly\n",
    "print(len(data)) # Should be 50,000\n",
    "print(type(data[0])) # Should be numpy.ndarray\n",
    "print(data[0].shape) # Should be 32x32 pixels and RGB (3 color channels) *All images must be the same shape to pass through the neural network*"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:34.565902Z",
     "start_time": "2023-12-27T21:26:34.556674Z"
    }
   },
   "id": "a679e7b61cf02e23"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Convert images list and labels list to numpy arrays\n",
    "X = np.array(data)\n",
    "Y = np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:34.734366Z",
     "start_time": "2023-12-27T21:26:34.561586Z"
    }
   },
   "id": "8cf6caddc7bcd0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Train Test Split*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dd20dc14715eb1"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2) # Using 20% of images as test data, 80% as training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:34.827666Z",
     "start_time": "2023-12-27T21:26:34.737705Z"
    }
   },
   "id": "92c687d3e935fb7c"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Scaling the data \n",
    "X_train_scaled = X_train/255 \n",
    "X_test_scaled = X_test/255"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:35.541158Z",
     "start_time": "2023-12-27T21:26:34.825855Z"
    }
   },
   "id": "c8dce9c263511f9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building the neural network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "773f26fda0c48cf8"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 14:26:35.584802: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:39.739003Z",
     "start_time": "2023-12-27T21:26:35.541697Z"
    }
   },
   "id": "2303dc48f0af90d2"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 14:26:39.753232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "n_of_classes = 10\n",
    "\n",
    "# Setting up the layers of the neural network\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(32,32,3)), # 32x32px, RGB\n",
    "    keras.layers.Dense(64, activation='relu'), # 64 neurons to efficiently maximize RAM usage, Rectified linear units\n",
    "    keras.layers.Dense(n_of_classes, activation='softmax') # Since nOfClasses > 2 we use 'softmax' not 'sigmoid'\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:39.870711Z",
     "start_time": "2023-12-27T21:26:39.740643Z"
    }
   },
   "id": "34698385bf818ee3"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:26:40.055533Z",
     "start_time": "2023-12-27T21:26:39.999434Z"
    }
   },
   "id": "f6184c58718e3c2"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1125/1125 [==============================] - 4s 4ms/step - loss: 1.9489 - acc: 0.3008 - val_loss: 1.8396 - val_acc: 0.3352\n",
      "Epoch 2/10\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 1.8309 - acc: 0.3468 - val_loss: 1.7938 - val_acc: 0.3517\n",
      "Epoch 3/10\n",
      "1125/1125 [==============================] - 2s 1ms/step - loss: 1.7847 - acc: 0.3638 - val_loss: 1.7864 - val_acc: 0.3582\n",
      "Epoch 4/10\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 1.7456 - acc: 0.3771 - val_loss: 1.7265 - val_acc: 0.3762\n",
      "Epoch 5/10\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 1.7303 - acc: 0.3832 - val_loss: 1.7346 - val_acc: 0.3742\n",
      "Epoch 6/10\n",
      "1125/1125 [==============================] - 2s 1ms/step - loss: 1.7085 - acc: 0.3899 - val_loss: 1.7099 - val_acc: 0.3895\n",
      "Epoch 7/10\n",
      "1125/1125 [==============================] - 2s 2ms/step - loss: 1.6891 - acc: 0.3930 - val_loss: 1.6670 - val_acc: 0.4038\n",
      "Epoch 8/10\n",
      "1125/1125 [==============================] - 2s 1ms/step - loss: 1.6772 - acc: 0.3974 - val_loss: 1.6904 - val_acc: 0.3918\n",
      "Epoch 9/10\n",
      "1125/1125 [==============================] - 2s 1ms/step - loss: 1.6618 - acc: 0.4032 - val_loss: 1.6804 - val_acc: 0.3988\n",
      "Epoch 10/10\n",
      "1125/1125 [==============================] - 2s 1ms/step - loss: 1.6565 - acc: 0.4054 - val_loss: 1.7021 - val_acc: 0.3873\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fb155636640>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the neural network\n",
    "model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=10) # Model will try to find the relationship between labels (Y_train) and images (X_train_scaled), Model will go through data 10 times"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:27:01.097436Z",
     "start_time": "2023-12-27T21:26:39.999974Z"
    }
   },
   "id": "f3a6b256eeafbd9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Was able to achieve accuracy of ~= 40% (not ideal). Now, moving on to transfer learning technique using ResNet50"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71cba259509d2cfb"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, models, layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras import optimizers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:27:01.175545Z",
     "start_time": "2023-12-27T21:27:01.096240Z"
    }
   },
   "id": "96a30866ca123a26"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "convolutional_base = ResNet50(weights='imagenet', include_top=False, input_shape=(256,256,3)) # ResNet50 needs images in size 256x256 px"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:27:02.558113Z",
     "start_time": "2023-12-27T21:27:01.149591Z"
    }
   },
   "id": "f603d6f3f1376415"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.UpSampling2D(size=(2,2))) # Converting from 32x32 px to 64x64 px\n",
    "model.add(layers.UpSampling2D(size=(2,2))) # Converting from 64x64 px to 128x128 px\n",
    "model.add(layers.UpSampling2D(size=(2,2))) # Converting from 128x128 px to 256x256 px -- We now have a compatible image size for use with ResNet50 \n",
    "model.add(convolutional_base)\n",
    "model.add(layers.Flatten()) # Convert matrix to vector so all values are in the form of a single column\n",
    "model.add(layers.BatchNormalization()) # Even though we already scaled data we still do this so performance increases\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5)) # Turn off a few neurons so model does not over-fit\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(n_of_classes, activation='softmax')) # Output layer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:27:02.575514Z",
     "start_time": "2023-12-27T21:27:02.558031Z"
    }
   },
   "id": "ff2f1c8f5344cd0a"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5), loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:27:02.579466Z",
     "start_time": "2023-12-27T21:27:02.575617Z"
    }
   },
   "id": "4f5db60db0909072"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, Y_train, validation_split=0.1, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:27:02.585296Z",
     "start_time": "2023-12-27T21:27:02.579867Z"
    }
   },
   "id": "3fc8eb9f561c4976"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T21:27:02.586042Z",
     "start_time": "2023-12-27T21:27:02.582114Z"
    }
   },
   "id": "9fb10a5f78b349fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
